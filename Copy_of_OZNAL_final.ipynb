{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of OZNAL_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xszaraz/oznal/blob/master/Copy_of_OZNAL_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92HRK79E2Ixx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZhb3HGI3Pi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/gdrive/My Drive/dataset'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ19DDJb6Yyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utdhckkFzbvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats as sm_stats\n",
        "import statsmodels.stats.api as sms\n",
        "import math as mth\n",
        "\n",
        "hospital_df = pd.read_csv(\"/content/gdrive/My Drive/dataset/hospital.csv\")\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "pd.set_option('max_colwidth', 999)\n",
        "hospital_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJQoFsWTzbvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df.loc[hospital_df['Total Costs'].between(0,10000), 'Total Costs'] = 1\n",
        "hospital_df.loc[hospital_df['Total Costs'].between(10000.01,20000), 'Total Costs'] = 2\n",
        "hospital_df.loc[hospital_df['Total Costs'] > 20000.01, 'Total Costs'] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7USFMf2Xzbvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['Total Costs'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QvVthcvzbv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df = hospital_df.drop(columns=['Ethnicity','Health Service Area','Hospital County','Facility Name', 'Facility Id', 'Zip Code - 3 digits', 'Operating Certificate Number', 'Discharge Year', 'CCS Diagnosis Code', 'CCS Procedure Code', 'APR DRG Code', 'APR MDC Code', 'APR Severity of Illness Code', 'Payment Typology 1', 'Payment Typology 2', 'Payment Typology 3', 'Total Charges'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uS1rUC2zbv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yMYDMPrzbv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if some values contains null\n",
        "hospital_df['Age Group'].isnull().values.any()\n",
        "hospital_df['Gender'].isnull().values.any()\n",
        "hospital_df['Race'].isnull().values.any()\n",
        "hospital_df['Length of Stay'].isnull().values.any()\n",
        "hospital_df['Type of Admission'].isnull().values.any()\n",
        "hospital_df['Patient Disposition'].isnull().values.any()\n",
        "hospital_df['CCS Diagnosis Description'].isnull().values.any()\n",
        "hospital_df['CCS Procedure Description'].isnull().values.any()\n",
        "hospital_df['APR DRG Description'].isnull().values.any()\n",
        "hospital_df['APR MDC Description'].isnull().values.any()\n",
        "hospital_df['APR Medical Surgical Description'].isnull().values.any()\n",
        "hospital_df['Birth Weight'].isnull().values.any()\n",
        "hospital_df['Abortion Edit Indicator'].isnull().values.any()\n",
        "hospital_df['Emergency Department Indicator'].isnull().values.any()\n",
        "hospital_df['Total Costs'].isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD920A24zbv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check how much values is missing\n",
        "hospital_df['APR Severity of Illness Description'].isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvo_gfdTzbwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check how much values is missing\n",
        "hospital_df['APR Risk of Mortality'].isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBUbeJshzbwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the rows with missing values \n",
        "hospital_df[hospital_df['APR Severity of Illness Description'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHWczuiSzbwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['APR Severity of Illness Description'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJTG6hhVzbwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['APR Risk of Mortality'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-aWfD-LzbwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fill the NaN values \n",
        "hospital_df['APR Severity of Illness Description'].fillna( method ='ffill', inplace = True) \n",
        "hospital_df['APR Risk of Mortality'].fillna( method ='ffill', inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_COq6OczbwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['APR Severity of Illness Description'].isnull().values.any()\n",
        "hospital_df['APR Risk of Mortality'].isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fih2uKmzbwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['CCS Diagnosis Description'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePq0AfWrzbwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#replace samples with counts lower than 3500 with Other \n",
        "keys = hospital_df['CCS Diagnosis Description'].value_counts().keys()\n",
        "\n",
        "for i in keys:\n",
        "    if hospital_df['CCS Diagnosis Description'][hospital_df['CCS Diagnosis Description'] == i].count() <= 3500:\n",
        "        hospital_df['CCS Diagnosis Description'] = hospital_df['CCS Diagnosis Description'].replace(i, \"Other\") \n",
        "        \n",
        "hospital_df['CCS Diagnosis Description'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y03edcF3zbwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['APR DRG Description'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PruNRHHBzbwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#replace samples with counts lower than 3500 with Other \n",
        "keys = hospital_df['APR DRG Description'].value_counts().keys()\n",
        "\n",
        "for i in keys:\n",
        "    if hospital_df['APR DRG Description'][hospital_df['APR DRG Description'] == i].count() <= 3500:\n",
        "        hospital_df['APR DRG Description'] = hospital_df['APR DRG Description'].replace(i, \"Other\") \n",
        "        \n",
        "hospital_df['APR DRG Description'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "edEOdX1Czbw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hospital_df['APR MDC Description'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttA_DYeQOXqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We have 2 346 931 samples, but we dont want to predict on all of them because of the time its gonna take\n",
        " \n",
        "#1368957 has value 1 and thats around 58 % of all samples from 2 346 931 samples\n",
        "#548392 has value 2 and thats around 23 % all samples from 2 346 931 samples\n",
        "#429582 has value 2 and thats around 19 %  all samples from 2 346 931 samples\n",
        "\n",
        "#500 000 samples will form our new dataset for predicting and training\n",
        "#290 000 samples in this new dataset will have value 1\n",
        "#115 000 samples in this new dataset will have value 2\n",
        "#95 000 samples in this new dataset will have value 3\n",
        "\n",
        "#1000 samples will form our new dataset for finding best hyperparameters\n",
        "#580 samples in this new dataset will have value 1\n",
        "#230 samples in this new dataset will have value 1\n",
        "#190 samples in this new dataset will have value 1\n",
        "\n",
        "#for sample picking we will use dataset.sample()\n",
        "\n",
        "dataset1 = hospital_df[hospital_df['Total Costs'] == 1]\n",
        "to_merge1 = dataset1.sample(n = 290000)\n",
        "to_hyperparameter1 = dataset1.sample(n = 580)\n",
        "dataset2 = hospital_df[hospital_df['Total Costs'] == 2]\n",
        "to_merge2 = dataset2.sample(n = 115000)\n",
        "to_hyperparameter2 = dataset2.sample(n = 230)\n",
        "dataset3 = hospital_df[hospital_df['Total Costs'] == 3]\n",
        "to_merge3 = dataset3.sample(n = 95000)\n",
        "to_hyperparameter3 = dataset3.sample(n = 190)\n",
        "\n",
        "dataset_merged = pd.concat([to_merge1, to_merge2, to_merge3])\n",
        "dataset_mergedhyperparameters = pd.concat([to_hyperparameter1, to_hyperparameter2, to_hyperparameter3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OilXfb_Xzbw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OneHotEncoding\n",
        "dm_dummies1 = pd.get_dummies(dataset_merged['Age Group'])\n",
        "dm_dummies2 = pd.get_dummies(dataset_merged['Gender'])\n",
        "dm_dummies3 = pd.get_dummies(dataset_merged['Race'])\n",
        "dm_dummies4 = pd.get_dummies(dataset_merged['Type of Admission'])\n",
        "dm_dummies5 = pd.get_dummies(dataset_merged['Patient Disposition'])\n",
        "dm_dummies6 = pd.get_dummies(dataset_merged['CCS Diagnosis Description'])\n",
        "dm_dummies7 = pd.get_dummies(dataset_merged['CCS Procedure Description'])\n",
        "dm_dummies8 = pd.get_dummies(dataset_merged['APR DRG Description'])\n",
        "dm_dummies9 = pd.get_dummies(dataset_merged['APR MDC Description'])\n",
        "dm_dummies10 = pd.get_dummies(dataset_merged['APR Severity of Illness Description'])\n",
        "dm_dummies11 = pd.get_dummies(dataset_merged['APR Risk of Mortality'])\n",
        "dm_dummies12 = pd.get_dummies(dataset_merged['APR Medical Surgical Description'])\n",
        "dm_dummies13 = pd.get_dummies(dataset_merged['Abortion Edit Indicator'])\n",
        "dm_dummies14 = pd.get_dummies(dataset_merged['Emergency Department Indicator'])\n",
        "\n",
        "dmhp_dummies1 = pd.get_dummies(dataset_mergedhyperparameters['Age Group'])\n",
        "dmhp_dummies2 = pd.get_dummies(dataset_mergedhyperparameters['Gender'])\n",
        "dmhp_dummies3 = pd.get_dummies(dataset_mergedhyperparameters['Race'])\n",
        "dmhp_dummies4 = pd.get_dummies(dataset_mergedhyperparameters['Type of Admission'])\n",
        "dmhp_dummies5 = pd.get_dummies(dataset_mergedhyperparameters['Patient Disposition'])\n",
        "dmhp_dummies6 = pd.get_dummies(dataset_mergedhyperparameters['CCS Diagnosis Description'])\n",
        "dmhp_dummies7 = pd.get_dummies(dataset_mergedhyperparameters['CCS Procedure Description'])\n",
        "dmhp_dummies8 = pd.get_dummies(dataset_mergedhyperparameters['APR DRG Description'])\n",
        "dmhp_dummies9 = pd.get_dummies(dataset_mergedhyperparameters['APR MDC Description'])\n",
        "dmhp_dummies10 = pd.get_dummies(dataset_mergedhyperparameters['APR Severity of Illness Description'])\n",
        "dmhp_dummies11 = pd.get_dummies(dataset_mergedhyperparameters['APR Risk of Mortality'])\n",
        "dmhp_dummies12 = pd.get_dummies(dataset_mergedhyperparameters['APR Medical Surgical Description'])\n",
        "dmhp_dummies13 = pd.get_dummies(dataset_mergedhyperparameters['Abortion Edit Indicator'])\n",
        "dmhp_dummies14 = pd.get_dummies(dataset_mergedhyperparameters['Emergency Department Indicator'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy0tZarczbw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#merging OneHotEncoding with the dataset from which OneHotEncodings were made\n",
        "merged_df = pd.concat([dataset_merged, dm_dummies1, dm_dummies2, dm_dummies3, dm_dummies4, dm_dummies5, dm_dummies6, dm_dummies7, dm_dummies8, dm_dummies9, dm_dummies10, dm_dummies11, dm_dummies12, dm_dummies13, dm_dummies14], axis = 'columns')\n",
        "merged_df_hp = pd.concat([dataset_mergedhyperparameters, dmhp_dummies1, dmhp_dummies2, dmhp_dummies3, dmhp_dummies4, dmhp_dummies5, dmhp_dummies6, dmhp_dummies7, dmhp_dummies8, dmhp_dummies9, dmhp_dummies10, dmhp_dummies11, dmhp_dummies12, dmhp_dummies13, dmhp_dummies14], axis = 'columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN2ykUgxzbxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping the original columns from which OneHotEncodings were made and replacing 120 + with 120 for training and predictioning \n",
        "features = merged_df.drop(columns=['Age Group', 'Gender', 'Race', 'Type of Admission', 'Patient Disposition', 'CCS Diagnosis Description', 'CCS Procedure Description', 'APR DRG Description', 'APR MDC Description', 'APR Severity of Illness Description', 'APR Risk of Mortality', 'APR Medical Surgical Description', 'Abortion Edit Indicator', 'Emergency Department Indicator'])\n",
        "features['Length of Stay'] = features['Length of Stay'].replace('120 +', '120')\n",
        "\n",
        "features2 = merged_df_hp.drop(columns=['Age Group', 'Gender', 'Race', 'Type of Admission', 'Patient Disposition', 'CCS Diagnosis Description', 'CCS Procedure Description', 'APR DRG Description', 'APR MDC Description', 'APR Severity of Illness Description', 'APR Risk of Mortality', 'APR Medical Surgical Description', 'Abortion Edit Indicator', 'Emergency Department Indicator'])\n",
        "features2['Length of Stay'] = features2['Length of Stay'].replace('120 +', '120')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qloe-65VzbxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Labels are the values we want to predict\n",
        "labels = np.array(features['Total Costs'])\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "features = features.drop('Total Costs', axis = 1)\n",
        "# Saving feature names for later use\n",
        "feature_list = list(features.columns)\n",
        "# Convert to numpy array\n",
        "features = np.array(features)\n",
        "\n",
        "# Labels2 are the values we want to predict\n",
        "labels2 = np.array(features2['Total Costs'])\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "features2 = features2.drop('Total Costs', axis = 1)\n",
        "# Saving feature names for later use\n",
        "feature_list2 = list(features2.columns)\n",
        "# Convert to numpy array\n",
        "features2 = np.array(features2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXWg--EtzbxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyHxinrRzbxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating arrays for model comparising \n",
        "models = []\n",
        "accuraccies = []\n",
        "recalls = []\n",
        "names = []\n",
        "y_preds = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNmd8inkzbxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting datas for training, predicting and hyperparamaters searching\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2, labels2, test_size = 0.25, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8zs9xkWC450",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype(int)\n",
        "X_test = X_test.astype(int)\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "X_train2 = X_train2.astype(int)\n",
        "X_test2 = X_test2.astype(int)\n",
        "y_train2 = y_train2.astype(int)\n",
        "y_test2 = y_test2.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdAjWFavzbxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Features Shape:', X_train.shape)\n",
        "print('Training Labels Shape:', y_train.shape)\n",
        "print('Testing Features Shape:', X_test.shape)\n",
        "print('Testing Labels Shape:', y_test.shape)\n",
        "print('Training2 Features Shape:', X_train2.shape)\n",
        "print('Training2 Labels Shape:', y_train2.shape)\n",
        "print('Testing2 Features Shape:', X_test2.shape)\n",
        "print('Testing2 Labels Shape:', y_test2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0wsDBv8zbxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz1SM7DYzbxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.get_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhCuDXVLzbxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GridSearchCV for RandomForestClassifier parameters\n",
        "\n",
        "#The number of trees in the forest\n",
        "n_estimators = [100, 300,700, 1200]\n",
        "#The maximum depth of the tree\n",
        "max_depth = [5, 10, 20, 40]\n",
        "#The minimum number of samples required to split an internal node\n",
        "min_samples_split = [2, 5, 10, 30, 100]\n",
        "#The minimum number of samples required to be at a leaf node\n",
        "min_samples_leaf = [1, 2, 5, 10]\n",
        "\n",
        "\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "              'max_depth': max_depth,\n",
        "              'min_samples_split': min_samples_split,\n",
        "              'min_samples_leaf': min_samples_leaf}\n",
        "\n",
        "rf_grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
        "rf_grid.fit(X_train2, y_train2)\n",
        "print(rf_grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqsMpH40zbxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1OlAFA8zbxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RandomForestClassifier without optimalization\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txF51LXuzbxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUe0IBhXzbxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get numerical feature importances\n",
        "importances = list(clf.feature_importances_)\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "for i in feature_importances:\n",
        "    print(\"Variable: \" + i[0] + \", Importance: \" + str(i[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGxOk18-pl-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('RF')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNlQdi6Vzbxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYEWIoVNzbyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RandomForestClassifier with GridSearchCV\n",
        "clf_grid = RandomForestClassifier(n_estimators = 100, min_samples_split = 2, max_depth = 20, min_samples_leaf = 1)\n",
        "clf_grid.fit(X_train, y_train)\n",
        "y_pred = clf_grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVTrzxkTzbyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtBueUaQzbyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get numerical feature importances\n",
        "importances = list(clf_grid.feature_importances_)\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "for i in feature_importances:\n",
        "    print(\"Variable: \" + i[0] + \", Importance: \" + str(i[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDaFTbRkzbyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('RF_grid')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVA5DNd1zbyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z57q-yBzbyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GradientBoosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FXKRHFzzbyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_gbm = GradientBoostingClassifier()\n",
        "clf_gbm.get_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW6DF3eozbya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GridSearchCV for GradientBoostingClassifier\n",
        "\n",
        "#Loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs\n",
        "loss = ['deviance']\n",
        "#Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators\n",
        "learning_rate = [1, 0.85, 0.5, 0.2, 0.05]\n",
        "#The number of boosting stages to perform\n",
        "n_estimators = [ 32, 64, 100, 200, 500]\n",
        "#Maximum depth of the individual regression estimators\n",
        "max_depth = [4, 6, 8, 10]\n",
        "#The fraction of samples to be used for fitting the individual base learners\n",
        "subsample = [0.6, 0.75, 0.85,0.9]\n",
        "\n",
        "param_grid = {'loss': loss,\n",
        "              'learning_rate': learning_rate,\n",
        "              'n_estimators': n_estimators,\n",
        "              'max_depth': max_depth,\n",
        "              'subsample': subsample}\n",
        "\n",
        "gbm_grid = GridSearchCV(estimator=clf_gbm, param_grid=param_grid, cv=5)\n",
        "gbm_grid.fit(X_train2, y_train2)\n",
        "print(gbm_grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwVa_6D1zbye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "askaDCAwzbyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GradientBoosting without optimalization\n",
        "clf_gbm.fit(X_train, y_train)\n",
        "y_pred = clf_gbm.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBxqIRMSzbyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xol5ALXnvol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get numerical feature importances\n",
        "importances = list(clf_gbm.feature_importances_)\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "for i in feature_importances:\n",
        "    print(\"Variable: \" + i[0] + \", Importance: \" + str(i[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qncdw1pxzbym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('GB')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoW6bGGgzbyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tbhDhVHzby0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GradientBoosting with GridSearchCV \n",
        "clf_gbm_grid = GradientBoostingClassifier(learning_rate = 0.05, loss = 'deviance',  max_depth = 6, n_estimators = 64, subsample = 0.75)\n",
        "clf_gbm_grid.fit(X_train, y_train)\n",
        "y_pred = clf_gbm_grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2RNT64Zzby4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfy0QsdsnxsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get numerical feature importances\n",
        "importances = list(clf_gbm_grid.feature_importances_)\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "for i in feature_importances:\n",
        "    print(\"Variable: \" + i[0] + \", Importance: \" + str(i[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsz7_cEpzby7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('GB_grid')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27M__eq5zby8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyLWSY6xzbzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MLogisticRegression \n",
        "from sklearn import linear_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np2IMEDPhLIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = linear_model.LogisticRegression()\n",
        "lr.get_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bgEdtEyh4kY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GridSearch for LogisticRegression\n",
        "\n",
        "#Used to specify the norm used in the penalization\n",
        "penalty = ['l1', 'l2']\n",
        "#Inverse of regularization strength\n",
        "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "#Algorithm to use in the optimization problem, saga because it can handle both l1 and l2 penalty\n",
        "solver = ['liblinear','saga']\n",
        "#For multinomial the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary\n",
        "multi_class = ['ovr']\n",
        "\n",
        "param_grid = dict(penalty=penalty,\n",
        "                  C=C,\n",
        "                  solver=solver,\n",
        "                  multi_class=multi_class)\n",
        "\n",
        "mlr_grid = GridSearchCV(estimator = lr, param_grid=param_grid, verbose=1, n_jobs=-1, cv=5)\n",
        "mlr_grid.fit(X_train2, y_train2)\n",
        "print(mlr_grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgphaJcQlXXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A93pHeExzbzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lLogisticRegression without optimization\n",
        "ovr_lr = linear_model.LogisticRegression(multi_class = 'ovr')\n",
        "ovr_lr.fit(X_train, y_train)\n",
        "y_pred = ovr_lr.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhfdXheEiHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOojo6kyzbzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('OVR_lr')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tagDwXtimONg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvTuHYz7zbzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lLogisticRegression with optimization\n",
        "ovr_lr_grid = linear_model.LogisticRegression(multi_class = 'ovr', penalty = 'l2', solver = 'liblinear', C = 0.1)\n",
        "ovr_lr_grid.fit(X_train, y_train)\n",
        "y_pred = ovr_lr_grid.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6C547ALiHIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0soWIoQikSUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('OVR_lr_grid')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCBorKEZDlMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Y6oPdVkT3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITR5_1srALFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mord as m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fmu75qqAezJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ord_lr = m.LogisticIT()\n",
        "ord_lr.fit(X_train, y_train)\n",
        "y_pred = ord_lr.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='micro')\n",
        "print(\"Accuracy: \" + str(accuracy) + \", Recall(micro):\" + str(recall) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U522c2vM5rIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydbHWT7zHdUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models.append('ORD_lr')\n",
        "accuraccies.append(accuracy)\n",
        "recalls.append(recall)\n",
        "y_preds.append(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnuxm3DPJeUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8whuqujzbzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import cycle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5f7jmALq06w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiVDxzL_q1T-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = accuraccies.index(max(accuraccies))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi3tcFjjt8o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_best = y_preds[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LNNUDv7uCTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = models[index]\n",
        "best_model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HiOtQiBzbzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is needed for ROC curve\n",
        "y_test_roc = label_binarize(y_test, classes=[1, 2, 3])\n",
        "y_pred_roc = label_binarize(y_pred_best, classes=[1, 2, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJUA6HCQzbzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "# Vypocitanie ROC curve a ROC oblasti pre kazdu triedu\n",
        "lw = 2\n",
        "n_classes = y_test_roc.shape[1]\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_roc[:, i], y_pred_roc[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_roc.ravel(), y_pred_roc.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4h6E4CYDouV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(models)):\n",
        "    print(\"Model: \" + models[i] + \", Accuracy: \" + str(accuraccies[i]) + \", Recall(micro): \" + str(recalls[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMVZKxDFrWfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "objects = np.array(models)  \n",
        "y_pos = np.arange(len(objects))\n",
        "performance = np.array(accuraccies)  \n",
        "\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuraccies comparision')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8uEsgMas--x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "objects = np.array(models)  \n",
        "y_pos = np.arange(len(objects))\n",
        "performance = np.array(recalls)  \n",
        "\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recalls comparision')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMFaGxznzbzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#colleration\n",
        "df = hospital_df\n",
        "df['Age Group']=df['Age Group'].astype('category').cat.codes\n",
        "df['Gender']=df['Gender'].astype('category').cat.codes\n",
        "df['Race']=df['Race'].astype('category').cat.codes\n",
        "df['Type of Admission']=df['Type of Admission'].astype('category').cat.codes\n",
        "df['Patient Disposition']=df['Patient Disposition'].astype('category').cat.codes\n",
        "df['CCS Diagnosis Description']=df['CCS Diagnosis Description'].astype('category').cat.codes\n",
        "df['CCS Procedure Description']=df['CCS Procedure Description'].astype('category').cat.codes\n",
        "df['APR DRG Description']=df['APR DRG Description'].astype('category').cat.codes\n",
        "df['APR MDC Description']=df['APR MDC Description'].astype('category').cat.codes\n",
        "df['APR Severity of Illness Description']=df['APR Severity of Illness Description'].astype('category').cat.codes\n",
        "df['APR Risk of Mortality']=df['APR Risk of Mortality'].astype('category').cat.codes\n",
        "df['APR Medical Surgical Description']=df['APR Medical Surgical Description'].astype('category').cat.codes\n",
        "df['Abortion Edit Indicator']=df['Abortion Edit Indicator'].astype('category').cat.codes\n",
        "df['Emergency Department Indicator']=df['Emergency Department Indicator'].astype('category').cat.codes\n",
        "df.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}